# Replication of Does AI help humans make better decisions? (Imai et al., PNAS forthcoming)

This repository documents my replication of the empirical framework proposed by Kosuke Imai and co-authors in their paper:

Does AI help humans make better decisions? A statistical evaluation framework for experimental and observational studies.

#âœ¨ Motivation

To deepen my understanding of causal inference with AI-assisted decision-making.

To gain hands-on experience with MCMC estimation, Inverse Probability Weighting (IPW/AIPW), and policy learning techniques.

# Repository structure
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ 00_install.R # Robust installation (CRAN â†’ r-universe â†’ GitHub fallback)
â”‚ â”œâ”€â”€ 10_quick_mcmc_synth.R # MCMC route on synthetic data (saves RDS)
â”‚ â”œâ”€â”€ 20_psa_aipw.R # AIPW route on interim PSA data (illustration only)
â”‚ â””â”€â”€ 30_policy_learning.R # Policy learning (Î”loss weights, l01, monotone policy via Gurobi)
â”œâ”€â”€ report/
â”‚ â”œâ”€â”€ replication.Rmd # R Markdown source
â”‚ â””â”€â”€ replication.html # Rendered one-click report
â””â”€â”€ figures/
â””â”€â”€ mcmc_diagnostics.pdf # Exported figures (diagnostics, preference regions, etc.)
```

# ğŸ“Š What the report shows
- MCMC diagnostics on bundled synthetic data
- APCE via IPW (stable to knit, interpretable table output)
- AIPW illustration: Human+AI vs Human, AI vs Human bounds, and preference plots across FP:FN ratios
- Policy learning: Î”loss weights and a monotone â€œwhen to provide AI suggestionsâ€ policy

# âš ï¸ Notes
- PSA datasets bundled in aihuman are interim and for illustration only.
- MCMC results are read from saved RDS for reproducibility and speed.
- Policy learning requires a working Gurobi installation.
