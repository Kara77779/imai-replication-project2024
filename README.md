# Replication of Does AI help humans make better decisions? (Imai et al., PNAS forthcoming)

This repository documents my replication of the empirical framework proposed by Kosuke Imai and co-authors in their paper:

Does AI help humans make better decisions? A statistical evaluation framework for experimental and observational studies.

#‚ú® Motivation

To deepen my understanding of causal inference with AI-assisted decision-making.

To gain hands-on experience with MCMC estimation, Inverse Probability Weighting (IPW/AIPW), and policy learning techniques.

# Repository structure
README.md
-scripts/
00_install.R # Robust installation (CRAN ‚Üí r-universe ‚Üí GitHub fallback)
10_quick_mcmc_synth.R # MCMC route on synthetic data (saves RDS)
20_psa_aipw.R # AIPW route on interim PSA data (illustration only)
30_policy_learning.R # Policy learning (Œîloss weights, l01, monotone policy via Gurobi)
-report/
replication.Rmd # R Markdown source
replication.html # Rendered one-click report
-figures/
mcmc_diagnostics.pdf # Exported figures (diagnostics, preference regions, etc.)


# üìä What the report shows
- MCMC diagnostics on bundled synthetic data
- APCE via IPW (stable to knit, interpretable table output)
- AIPW illustration: Human+AI vs Human, AI vs Human bounds, and preference plots across FP:FN ratios
- Policy learning: Œîloss weights and a monotone ‚Äúwhen to provide AI suggestions‚Äù policy

# ‚ö†Ô∏è Notes
- PSA datasets bundled in aihuman are interim and for illustration only.
- MCMC results are read from saved RDS for reproducibility and speed.
- Policy learning requires a working Gurobi installation.
